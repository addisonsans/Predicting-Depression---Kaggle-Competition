{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "632f333d-93aa-4842-a647-dbdcce0ff9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import preprocessing tools\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import machine learning model and metrics\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Import warnings to handle potential deprication warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ac4a3bc-c8c1-470c-9a13-f871850dde3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "# Step 1: Categorize Sleep Duration if it exists\n",
    "def categorize_sleep_duration(value):\n",
    "    value = str(value).lower().replace('hours', '').strip()\n",
    "    if any(keyword in value for keyword in ['less than', '1-2', '2-3', '3-4', '4-5']):\n",
    "        return 'Short Sleep'\n",
    "    elif any(keyword in value for keyword in ['5-6', '6-7', '6-8', '7-8']):\n",
    "        return 'Adequate Sleep'\n",
    "    elif any(keyword in value for keyword in ['more than', '8-9', '9-10', '10-11']):\n",
    "        return 'Long Sleep'\n",
    "    try:\n",
    "        numeric_values = [float(x) for x in value.split() if x.replace('.', '', 1).isdigit()]\n",
    "        if numeric_values:\n",
    "            avg_hours = sum(numeric_values) / len(numeric_values)\n",
    "            if avg_hours < 5:\n",
    "                return 'Short Sleep'\n",
    "            elif 5 <= avg_hours <= 8:\n",
    "                return 'Adequate Sleep'\n",
    "            elif avg_hours > 8:\n",
    "                return 'Long Sleep'\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "    return np.nan\n",
    "\n",
    "# Step 2: Categorize `Dietary Habits` if it exists\n",
    "def categorize_dietary_habits(value):\n",
    "    value = str(value).lower().strip()\n",
    "    if 'healthy' in value or 'balanced' in value or 'nutritious' in value:\n",
    "        return 'Healthy'\n",
    "    elif 'moderate' in value:\n",
    "        return 'Moderate'\n",
    "    elif 'unhealthy' in value or 'junk' in value or 'fast food' in value:\n",
    "        return 'Unhealthy'\n",
    "    return np.nan\n",
    "\n",
    "# Apply custom categorizations to the dataset, only if the columns exist\n",
    "def apply_custom_categorizations(data):\n",
    "    if 'Sleep Duration' in data.columns:\n",
    "        data['Sleep Duration'] = data['Sleep Duration'].apply(categorize_sleep_duration)\n",
    "    if 'Dietary Habits' in data.columns:\n",
    "        data['Dietary Habits'] = data['Dietary Habits'].apply(categorize_dietary_habits)\n",
    "    return data\n",
    "\n",
    "# Step 3: Impute and Clean Data\n",
    "def impute_and_clean_data(data):\n",
    "    # Drop irrelevant columns\n",
    "    data.drop(columns=['id', 'Name', 'City', 'Profession', 'Degree'], errors='ignore', inplace=True)\n",
    "    \n",
    "    # Handle columns based on `Working Professional or Student` status, if available\n",
    "    if 'Working Professional or Student' in data.columns:\n",
    "        data['Study Satisfaction'] = data.apply(lambda row: row['Study Satisfaction'] if row['Working Professional or Student'] == 'Student' else 0, axis=1)\n",
    "        data['CGPA'] = data.apply(lambda row: row['CGPA'] if row['Working Professional or Student'] == 'Student' else 0, axis=1)\n",
    "        data['Job Satisfaction'] = data.apply(lambda row: row['Job Satisfaction'] if row['Working Professional or Student'] == 'Working Professional' else 0, axis=1)\n",
    "        data['Work Pressure'] = data.apply(lambda row: row['Work Pressure'] if row['Working Professional or Student'] == 'Working Professional' else 0, axis=1)\n",
    "    \n",
    "    # Fill numeric NaNs with the median\n",
    "    numeric_columns = data.select_dtypes(include=['number']).columns\n",
    "    data[numeric_columns] = data[numeric_columns].fillna(data[numeric_columns].median())\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Step 4: One-Hot Encoding\n",
    "def one_hot_encode(data, categorical_columns):\n",
    "    # Filter only columns that exist in the data\n",
    "    existing_categorical_columns = [col for col in categorical_columns if col in data.columns]\n",
    "    \n",
    "    if existing_categorical_columns:\n",
    "        encoder = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "        encoded_data = encoder.fit_transform(data[existing_categorical_columns])\n",
    "        encoded_df = pd.DataFrame(encoded_data.toarray(), columns=encoder.get_feature_names_out(existing_categorical_columns))\n",
    "        data = pd.concat([data.drop(columns=existing_categorical_columns), encoded_df], axis=1)\n",
    "    else:\n",
    "        print(\"No categorical columns found for encoding.\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Step 5: Full Preprocessing Pipeline\n",
    "def preprocess_data(file_path, categorical_columns):\n",
    "    data = load_data(file_path)\n",
    "    data = apply_custom_categorizations(data)\n",
    "    data = impute_and_clean_data(data)\n",
    "    data = one_hot_encode(data, categorical_columns)\n",
    "    return data\n",
    "\n",
    "# Apply the preprocessing function to the training and test datasets\n",
    "categorical_columns = ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', \n",
    "                       'Family History of Mental Illness', 'Sleep Duration', 'Dietary Habits']\n",
    "\n",
    "# Example usage:\n",
    "train_data = preprocess_data('depression_detection_train.csv', categorical_columns)\n",
    "test_data = preprocess_data('depression_prediction_test.csv', categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a966110-5509-4372-ba55-ee6e442f2b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9425657427149965\n",
      "Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97    115133\n",
      "           1       0.86      0.82      0.84     25567\n",
      "\n",
      "    accuracy                           0.94    140700\n",
      "   macro avg       0.91      0.90      0.90    140700\n",
      "weighted avg       0.94      0.94      0.94    140700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Separate features and target variable from the training data\n",
    "X_train = train_data.drop(columns=['Depression'], errors='ignore')\n",
    "y_train = train_data['Depression']\n",
    "\n",
    "# Define the model using the original parameters that performed well\n",
    "xgb_model = XGBClassifier(\n",
    "    subsample=0.9,\n",
    "    n_estimators=300,\n",
    "    max_depth=5,  # Adjust to previous best setting if known\n",
    "    learning_rate=0.1,  # Adjust if your previous best learning rate is different\n",
    "    gamma=0.0,  # Use the original gamma setting\n",
    "    colsample_bytree=0.8,  # Use the previous colsample_bytree if known\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on training data\n",
    "y_train_pred = xgb_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Training Classification Report:\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "# Load the raw test data to retain the `id` column\n",
    "test_data_raw = pd.read_csv('depression_prediction_test.csv')\n",
    "\n",
    "# Preprocess the test data separately, ensuring we do not drop 'id' during preprocessing\n",
    "test_data_preprocessed = preprocess_data('depression_prediction_test.csv', categorical_columns)\n",
    "\n",
    "# Generate predictions on the preprocessed test data\n",
    "test_predictions = xgb_model.predict(test_data_preprocessed)\n",
    "\n",
    "# Prepare the output for submission using 'id' from the raw test data\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_data_raw['id'],  # Use the 'id' column from the raw test data\n",
    "    'Depression': test_predictions\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv('submission_xgboost_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1636384-2ed5-41f1-b9d0-4db21d674407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best Parameters: {'subsample': 1.0, 'reg_lambda': 2, 'reg_alpha': 0, 'n_estimators': 400, 'min_child_weight': 7, 'max_depth': 3, 'learning_rate': 0.15, 'gamma': 0.2, 'colsample_bytree': 0.6}\n",
      "Best Cross-Validation Accuracy: 0.9376830135039089\n",
      "Training Accuracy with Best Model: 0.9387135749822317\n",
      "Training Classification Report with Best Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96    115133\n",
      "           1       0.84      0.81      0.83     25567\n",
      "\n",
      "    accuracy                           0.94    140700\n",
      "   macro avg       0.90      0.89      0.90    140700\n",
      "weighted avg       0.94      0.94      0.94    140700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'min_child_weight': [1, 3, 5, 7],\n",
    "    'reg_alpha': [0, 0.01, 0.1, 1],\n",
    "    'reg_lambda': [1, 1.5, 2, 3]\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "# Set up RandomizedSearchCV with cross-validation\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,  # Adjust this number to search more/less combinations\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Perform the search on the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score achieved\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Cross-Validation Accuracy:\", best_score)\n",
    "\n",
    "# Train the model with the best parameters found\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the training data with the best model\n",
    "y_train_pred = best_xgb_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training Accuracy with Best Model:\", train_accuracy)\n",
    "print(\"Training Classification Report with Best Model:\")\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8638ea71-ffe2-46fa-be9a-aef34f2ae033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87816cff-e995-4784-905c-e8c4c6a5dfd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
